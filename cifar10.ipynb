{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12bec279",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import requests\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "torch.manual_seed(1) # Set manual seed\n",
    "from sklearn import preprocessing\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "\n",
    "# Define GPU device - We will run our model on GPU\n",
    "mps_device = torch.device(\"cuda\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa191eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 32\n",
    "\n",
    "mean, std = [0.4914, 0.4822, 0.4465], [0.247, 0.243, 0.261]\n",
    "# These values are mostly used by researchers as found to very useful in fast convergence\n",
    "\n",
    "\n",
    "# https://pytorch.org/vision/stable/transforms.html\n",
    "# We can try various transformation for good generalization of model\n",
    "composed_train = transforms.Compose([transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)), # Resize the image in a 32X32 shape\n",
    "                                     transforms.RandomRotation(20), # Randomly rotate some images by 20 degrees\n",
    "                                     transforms.RandomHorizontalFlip(0.1), # Randomly horizontal flip the images\n",
    "                                     transforms.ColorJitter(brightness = 0.1, # Randomly adjust color jitter of the images\n",
    "                                                            contrast = 0.1, \n",
    "                                                            saturation = 0.1), \n",
    "                                     transforms.RandomAdjustSharpness(sharpness_factor = 2,\n",
    "                                                                      p = 0.1), # Randomly adjust sharpness\n",
    "                                     transforms.ToTensor(),   # Converting image to tensor\n",
    "                                     transforms.Normalize(mean, std), # Normalizing with standard mean and standard deviation\n",
    "                                     transforms.RandomErasing(p=0.75,scale=(0.02, 0.1),value=1.0, inplace=False)])\n",
    "\n",
    "\n",
    "composed_test = transforms.Compose([transforms.Resize((IMAGE_SIZE,IMAGE_SIZE)),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean, std)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cbabe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data and transform the dataset\n",
    "train_dataset =  dsets.CIFAR10(root='./data', train=True, download=True, transform = composed_train)\n",
    "validation_dataset = dsets.CIFAR10(root='./data', train=False, download=True, transform = composed_test)\n",
    "\n",
    "# Create train and validation batch for training\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=100)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1d0c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_data(img):\n",
    "    try:\n",
    "        plt.imshow(img[0])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    print(img[0].shape, img[0].permute(1,2,0).shape)\n",
    "    plt.imshow(img[0].permute(1,2,0))\n",
    "    plt.title('y = '+ str(img[1]))\n",
    "    plt.show()\n",
    "    \n",
    "# We need to convert the images to numpy arrays as tensors are not compatible with matplotlib.\n",
    "def im_convert(tensor):\n",
    "    #Lets\n",
    "    img = tensor.cpu().clone().detach().numpy() #\n",
    "    img = img.transpose(1, 2, 0)\n",
    "    img = img * np.array(tuple(mean)) + np.array(tuple(std))\n",
    "    img = img.clip(0, 1) # Clipping the size to print the images later\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c73c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, validation_loader, optimizer, n_epochs = 20):\n",
    "    \n",
    "    # Global variable\n",
    "    N_test = len(validation_dataset)\n",
    "    accuracy_list = []\n",
    "    train_loss_list = []\n",
    "    model = model.to(mps_device)\n",
    "    train_cost_list = []\n",
    "    val_cost_list = []\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        train_COST = 0\n",
    "        for x,y in train_loader:\n",
    "            x = x.to(mps_device)\n",
    "            y = y.to(mps_device)\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            z = model(x)\n",
    "            loss = criterion(z,y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_COST+=loss.item()\n",
    "            \n",
    "        train_COST = train_COST/len(train_loader)\n",
    "        train_cost_list.append(train_COST)\n",
    "        correct = 0\n",
    "        \n",
    "        # Perform the prediction on the validation data\n",
    "        val_COST = 0\n",
    "        for x_test, y_test in validation_loader:\n",
    "            model.eval()\n",
    "            x_test = x_test.to(mps_device)\n",
    "            y_test = y_test.to(mps_device)\n",
    "            z = model(x_test)\n",
    "            val_loss = criterion(z, y_test)\n",
    "            _, yhat = torch.max(z.data, 1)\n",
    "            correct += (yhat==y_test).sum().item()\n",
    "            val_COST+=val_loss.item()\n",
    "        \n",
    "        val_COST = val_COST/ len(validation_loader)\n",
    "        val_cost_list.append(val_COST)\n",
    "            \n",
    "        accuracy = correct / N_test\n",
    "        accuracy_list.append(accuracy)\n",
    "        \n",
    "        print(\"--> Epoch Number : {}\".format(epoch + 1),\n",
    "              \" | Training Loss : {}\".format(round(train_COST,4)),\n",
    "              \" | Validation Loss : {}\".format(round(val_COST,4)),\n",
    "              \" | Validation Accuracy : {}%\".format(round(accuracy * 100, 2)))\n",
    "        \n",
    "    return accuracy_list, train_cost_list, val_cost_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68af1e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    '''\n",
    "    CNN Model V1: \n",
    "    1. 2 convolution + max pool layers \n",
    "    2. 1 fully connected layers\n",
    "    3. Default runtime using 0 momentum and 0 dropout value\n",
    "    '''\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, out_1 = 32, out_2 = 64, number_of_classes = 10):\n",
    "        super(CNN, self).__init__()\n",
    "        self.cnn1 = nn.Conv2d(in_channels = 3, out_channels = out_1, kernel_size = 5, padding = 2)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size = 2)\n",
    "        \n",
    "        \n",
    "        self.cnn2 = nn.Conv2d(in_channels = out_1, out_channels = out_2, kernel_size = 5, padding = 2)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size = 2)\n",
    "        self.fc1 = nn.Linear(out_2 * 8 * 8, number_of_classes)\n",
    "        # Calculation of how we got 8*8 is mentioned in the below comment\n",
    "        \n",
    "    # Prediction\n",
    "    def forward(self, x):\n",
    "        x = self.cnn1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.cnn2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40db5ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = CNN(out_1=32, out_2=64, number_of_classes = 10)\n",
    "\n",
    "# Define model training hyperparameters\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "# Train the model\n",
    "accuracy_list_normal, train_cost_list, val_cost_list = train_model(model=model,n_epochs=20,train_loader=train_loader,validation_loader=validation_loader,optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42a3db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the model\n",
    "model_mmt = CNN(out_1=32, out_2=64, number_of_classes = 10)\n",
    "\n",
    "# Define the model learning hyperparameters\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.SGD(model_mmt.parameters(), lr = learning_rate, momentum = 0.2)\n",
    "\n",
    "# Train the model\n",
    "accuracy_list_normal_mmt, train_cost_list_mmt, val_cost_list_mmt=train_model(model=model_mmt,n_epochs=20,train_loader=train_loader,validation_loader=validation_loader,optimizer=optimizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e78cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_V2(nn.Module):    \n",
    "    '''\n",
    "    CNN Model V2: \n",
    "    1. 2 convolution & max pool layers \n",
    "    2. 2 fully connected layers\n",
    "    3. Default runtime using 0.2 momentum and dropout value p = 0.5\n",
    "    '''\n",
    "    # Constructor\n",
    "    def __init__(self, out_1 = 32, out_2 = 64, number_of_classes = 10, p = 0):\n",
    "        super(CNN_V2, self).__init__()\n",
    "        self.cnn1 = nn.Conv2d(in_channels = 3, out_channels = out_1, kernel_size = 5, padding = 2)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size = 2)\n",
    "        \n",
    "        \n",
    "        self.cnn2 = nn.Conv2d(in_channels = out_1, out_channels = out_2, kernel_size = 5, padding = 2)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size = 2)\n",
    "        self.fc1 = nn.Linear(out_2 * 8 * 8, 1000) # Roughly taken seein the input and the output\n",
    "        self.drop = nn.Dropout(p=p)\n",
    "        self.fc2 = nn.Linear(1000, number_of_classes)\n",
    "        \n",
    "    # Prediction\n",
    "    def forward(self, x):\n",
    "        x = self.cnn1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.cnn2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(self.drop(x))\n",
    "        x = self.fc2(x)\n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fda6718",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the model\n",
    "model_mmtv2 = CNN_V2(out_1=32, out_2=64, number_of_classes = 10, p=0.5)\n",
    "\n",
    "# Define model learning hyperparamters\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.SGD(model_mmtv2.parameters(), lr = learning_rate, momentum = 0.2)\n",
    "\n",
    "# Train the model\n",
    "accuracy_list_normal, train_cost_list, val_cost_list=train_model(model=model_mmtv2,n_epochs=20,train_loader=train_loader,validation_loader=validation_loader,optimizer=optimizer)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cifar10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
